{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75SOXkEl4lWE"
      },
      "source": [
        "# Predict Bike Sharing Demand with AutoGluon Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3uRm8J74lWZ"
      },
      "source": [
        "## Project: Predict Bike Sharing Demand with AutoGluon\n",
        "This notebook is a template with each step that you need to complete for the project.\n",
        "\n",
        "Please fill in your code where there are explicit `?` markers in the notebook. You are welcome to add more cells and code as you see fit.\n",
        "\n",
        "Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.\n",
        "\n",
        "`File-> Export Notebook As... -> Export Notebook as HTML`\n",
        "\n",
        "There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.\n",
        "\n",
        "Completing the code template and writeup template will cover all of the rubric points for this project.\n",
        "\n",
        "The rubric contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this notebook and also discuss the results in the writeup file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuEVPXhh4lWb"
      },
      "source": [
        "## Step 1: Create an account with Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iQwqV044lWc"
      },
      "source": [
        "### Create Kaggle Account and download API key\n",
        "Below is example of steps to get the API username and key. Each student will have their own username and key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBAh02oN4lWe"
      },
      "source": [
        "1. Open account settings.\n",
        "![kaggle1.png](attachment:kaggle1.png)\n",
        "![kaggle2.png](attachment:kaggle2.png)\n",
        "2. Scroll down to API and click Create New API Token.\n",
        "![kaggle3.png](attachment:kaggle3.png)\n",
        "![kaggle4.png](attachment:kaggle4.png)\n",
        "3. Open up `kaggle.json` and use the username and key.\n",
        "![kaggle5.png](attachment:kaggle5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuyMJz2d4lWf"
      },
      "source": [
        "## Step 2: Download the Kaggle dataset using the kaggle python library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfYOzsEI4lWg"
      },
      "source": [
        "### Open up Sagemaker Studio and use starter template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbnYseUt4lWi"
      },
      "source": [
        "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
        "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3gJGJWT4lWk"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hhGBDFfb4lWl",
        "outputId": "cc104bd4-7eaf-413b-a8c7-6ed82753bedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-67.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bokeh==2.0.1\n",
            "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (8.4.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (2.27.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet<2.0.0)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.4)\n",
            "Building wheels for collected packages: bokeh\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=c958da7c89149613888008855227f66b492e58e07ef9e9d98ac853293d7a156d\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754\n",
            "Successfully built bokeh\n",
            "Installing collected packages: graphviz, mxnet, bokeh\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 2.4.3\n",
            "    Uninstalling bokeh-2.4.3:\n",
            "      Successfully uninstalled bokeh-2.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.14.4 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting autogluon.core[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.3/218.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m209.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m306.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m277.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m251.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.22.4)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.2.2)\n",
            "Collecting networkx<3.0,>=2.3 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m202.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (2.27.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading boto3-1.26.150-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m297.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==0.7.0 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m195.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (0.2.7)\n",
            "Collecting ray[tune]<2.3,>=2.2 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<9.6,>=9.3 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m216.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m158.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.4.0,>=0.2.2 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.17,>=0.9 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m310.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.7.0,>=0.6.12 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m337.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.14,>=1.9 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.15.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m236.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale<0.4.14,>=0.4.5 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m194.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Collecting pytorch-lightning<1.10.0,>=1.9.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m169.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<0.9.0,>=0.8.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m320.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.27.0,>=4.23.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m250.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m273.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m346.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m208.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m207.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>0.1.5 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (2.12.2)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting catboost<1.2,>=1.0 (from autogluon.tabular[all]==0.7.0->autogluon)\n",
            "  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lightgbm<3.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (3.3.5)\n",
            "Requirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (1.7.5)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (2.7.12)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: statsmodels<0.14,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.13.5)\n",
            "Collecting gluonts<0.13,>=0.12.0 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m206.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ujson<6,>=5 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sktime<0.16,>=0.14 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m143.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats<2,>=1.1 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m218.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima<1.9,>=1.8.2 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m302.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (67.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (6.0)\n",
            "Collecting botocore<1.30.0,>=1.29.150 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading botocore-1.29.150-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m285.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m223.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m339.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m263.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m308.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (2023.4.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m320.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.5.2)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (1.10.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.7.0->autogluon) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.7.0->autogluon) (0.40.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (2022.10.31)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m235.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.8.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2022.7.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (0.29.34)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (1.26.15)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.12.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.20.3)\n",
            "Collecting aiosignal (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m295.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv>=20.0.24 (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m165.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.54.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (3.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.7.0->autogluon) (3.1.0)\n",
            "Collecting deprecated>=1.2.13 (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.56.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.14,>=0.13.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.3.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m342.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m169.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m186.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyDeprecate==0.3.* (from torchmetrics<0.9.0,>=0.8.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.27.0,>=4.23.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m186.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (9.0.0)\n",
            "Collecting aiohttp (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m324.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.39.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.3.0)\n",
            "Collecting distlib<1,>=0.3.6 (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m313.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.3.0)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (8.2.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.14.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m187.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m183.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (1.7.1)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=429b4afa6e422d0496c7c23495ab6b7dafda701f7cade4c4433d9af6d32b3815\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fdo27hks/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a847cc31eba8ae270f903a72ec05ef515cfcecd211a22d16e33c06dd362ec078\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fdo27hks/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=547112bc42564a5732caa5f5b5c6645a0d82b1b7d0a4ffc9c39eecdd7afad616\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fdo27hks/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built fairscale antlr4-python3-runtime seqeval\n",
            "Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, responses, pytesseract, nvidia-cudnn-cu11, multiprocess, model-index, huggingface-hub, botocore, aiosignal, transformers, torch, seqeval, s3transfer, ray, openmim, gluonts, catboost, aiohttp, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, boto3, accelerate, timm, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.14.4 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 2.0.1 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.150 botocore-1.29.150 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.14 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.8 huggingface-hub-0.15.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.1 sentencepiece-0.1.99 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1 ujson-5.7.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
        "!pip install autogluon --no-cache-dir\n",
        "# Without --no-cache-dir, smaller aws instances may have trouble installing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvjZ-Wan4lWn"
      },
      "source": [
        "### Setup Kaggle API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uXppqr6e4lWo"
      },
      "outputs": [],
      "source": [
        "# create the .kaggle directory and an empty kaggle.json file\n",
        "!mkdir -p /root/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nqTDintO4lWp"
      },
      "outputs": [],
      "source": [
        "# Fill in your user name and key from creating the kaggle account and API token file\n",
        "import json\n",
        "kaggle_username = \"mohamedmohsen1017\"\n",
        "kaggle_key = \"f9aae88a3e4cb2cafefbf359a1bbb404\"\n",
        "\n",
        "# Save API token the kaggle.json file\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t51GKsb4lWq"
      },
      "source": [
        "### Download and explore dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsuRQaEo4lWq"
      },
      "source": [
        "### Go to the bike sharing demand competition and agree to the terms\n",
        "![kaggle6.png](attachment:kaggle6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24NH3dD94lWr",
        "outputId": "c1a1b653-917c-449b-9ff5-882d1ff90ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bike-sharing-demand.zip to /content\n",
            "\r  0% 0.00/189k [00:00<?, ?B/s]\n",
            "\r100% 189k/189k [00:00<00:00, 75.7MB/s]\n",
            "Archive:  bike-sharing-demand.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
        "!kaggle competitions download -c bike-sharing-demand\n",
        "# If you already downloaded it you can use the -o command to overwrite the file\n",
        "!unzip -o bike-sharing-demand.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Eevo3e6X4lWs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4jNTFxsZ4lWs",
        "outputId": "cba354b0-3c92-4025-9cad-10d195ee2255"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
              "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
              "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
              "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
              "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
              "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  casual  registered  count  \n",
              "0        81        0.0       3          13     16  \n",
              "1        80        0.0       8          32     40  \n",
              "2        80        0.0       5          27     32  \n",
              "3        75        0.0       3          10     13  \n",
              "4        75        0.0       0           1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6125d67-ec4b-446e-802b-0e9d55063bb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6125d67-ec4b-446e-802b-0e9d55063bb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6125d67-ec4b-446e-802b-0e9d55063bb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6125d67-ec4b-446e-802b-0e9d55063bb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Create the train dataset in pandas by reading the csv\n",
        "# Set the parsing of the datetime column so you can use some of the `dt` features in pandas later\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M55S5p5H4lWt"
      },
      "outputs": [],
      "source": [
        "# Simple output of the train dataset to view some of the min/max/varition of the dataset features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yXTytAa24lWu",
        "outputId": "2634a984-a861-4f3b-f3b8-01de9316adeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
              "0  2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
              "1  2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
              "2  2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
              "3  2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
              "4  2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
              "\n",
              "   humidity  windspeed  \n",
              "0        56    26.0027  \n",
              "1        56     0.0000  \n",
              "2        56     0.0000  \n",
              "3        56    11.0014  \n",
              "4        56    11.0014  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81ac7098-c182-49bb-ba7c-9ff0b6e4beb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>11.365</td>\n",
              "      <td>56</td>\n",
              "      <td>26.0027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81ac7098-c182-49bb-ba7c-9ff0b6e4beb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81ac7098-c182-49bb-ba7c-9ff0b6e4beb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81ac7098-c182-49bb-ba7c-9ff0b6e4beb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3F-b--IG4lWu",
        "outputId": "f6d8cfb3-a415-4b4b-8d68-7d2e9a960342"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  count\n",
              "0  2011-01-20 00:00:00      0\n",
              "1  2011-01-20 01:00:00      0\n",
              "2  2011-01-20 02:00:00      0\n",
              "3  2011-01-20 03:00:00      0\n",
              "4  2011-01-20 04:00:00      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d7eecfd-86f3-4e3b-af6a-866148e21781\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d7eecfd-86f3-4e3b-af6a-866148e21781')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d7eecfd-86f3-4e3b-af6a-866148e21781 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d7eecfd-86f3-4e3b-af6a-866148e21781');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Same thing as train and test dataset\n",
        "submission = pd.read_csv('/content/sampleSubmission.csv')\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liQvZSww4lWv"
      },
      "source": [
        "## Step 3: Train a model using AutoGluon’s Tabular Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPW6rrEA4lWx"
      },
      "source": [
        "Requirements:\n",
        "* We are prediting `count`, so it is the label we are setting.\n",
        "* Ignore `casual` and `registered` columns as they are also not present in the test dataset. \n",
        "* Use the `root_mean_squared_error` as the metric to use for evaluation.\n",
        "* Set a time limit of 10 minutes (600 seconds).\n",
        "* Use the preset `best_quality` to focus on creating the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hemjd_K4lWx",
        "outputId": "dae9210d-ea2c-4733-871e-eebf8629a427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230608_213303/\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230608_213303/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 11\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Dropping user-specified ignored columns: ['casual', 'registered']\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12074.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.52 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                        : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
            "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.3s = Fit runtime\n",
            "\t9 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.37s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.64s of the 599.6s of remaining time.\n",
            "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 392.33s of the 592.29s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 392.15s of the 592.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-131.4609\t = Validation score   (-root_mean_squared_error)\n",
            "\t94.25s\t = Training   runtime\n",
            "\t16.26s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 285.24s of the 485.19s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-131.0542\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.16s\t = Training   runtime\n",
            "\t3.32s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 236.75s of the 436.7s of remaining time.\n",
            "\t-116.5484\t = Validation score   (-root_mean_squared_error)\n",
            "\t18.38s\t = Training   runtime\n",
            "\t0.86s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 216.21s of the 416.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-130.7069\t = Validation score   (-root_mean_squared_error)\n",
            "\t174.9s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 37.51s of the 237.47s of remaining time.\n",
            "\t-124.6007\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.6s\t = Training   runtime\n",
            "\t0.82s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 24.63s of the 224.58s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-142.545\t = Validation score   (-root_mean_squared_error)\n",
            "\t56.81s\t = Training   runtime\n",
            "\t0.62s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 163.68s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 162.92s of the 162.9s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-60.2587\t = Validation score   (-root_mean_squared_error)\n",
            "\t78.32s\t = Training   runtime\n",
            "\t5.36s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 75.59s of the 75.57s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-55.1804\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.19s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 35.1s of the 35.08s of remaining time.\n",
            "\t-53.4389\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.48s\t = Training   runtime\n",
            "\t1.03s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -10.69s of remaining time.\n",
            "\t-53.16\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 611.03s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230608_213303/\")\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label=\"count\",eval_metric=\"root_mean_squared_error\",\n",
        "learner_kwargs={\"ignored_columns\": [\"casual\", \"registered\"]}).fit(train_data=train,\n",
        "time_limit=600, \n",
        "presets=\"best_quality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUpmUyt_4lWy"
      },
      "source": [
        "### Review AutoGluon's training run with ranking of models that did the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yexaxd8S4lWy",
        "outputId": "55641e4d-ec3a-427d-c875-be0750b19997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3  -53.159983      29.031099  556.514511                0.001137           0.307760            3       True         13\n",
            "1   RandomForestMSE_BAG_L2  -53.438930      23.252802  441.703147                1.033817          43.477255            2       True         12\n",
            "2          LightGBM_BAG_L2  -55.180352      22.632202  434.413855                0.413216          36.187963            2       True         11\n",
            "3        LightGBMXT_BAG_L2  -60.258733      27.582929  476.541534                5.363944          78.315642            2       True         10\n",
            "4    KNeighborsDist_BAG_L1  -84.125061       0.081367    0.057946                0.081367           0.057946            1       True          2\n",
            "5      WeightedEnsemble_L2  -84.125061       0.084985    0.764067                0.003618           0.706121            2       True          9\n",
            "6    KNeighborsUnif_BAG_L1 -101.546199       0.075797    0.059519                0.075797           0.059519            1       True          1\n",
            "7   RandomForestMSE_BAG_L1 -116.548359       0.860845   18.381736                0.860845          18.381736            1       True          5\n",
            "8     ExtraTreesMSE_BAG_L1 -124.600676       0.815030   10.604084                0.815030          10.604084            1       True          7\n",
            "9          CatBoost_BAG_L1 -130.706865       0.185692  174.902122                0.185692         174.902122            1       True          6\n",
            "10         LightGBM_BAG_L1 -131.054162       3.320137   43.160946                3.320137          43.160946            1       True          4\n",
            "11       LightGBMXT_BAG_L1 -131.460909      16.260931   94.248413               16.260931          94.248413            1       True          3\n",
            "12  NeuralNetFastAI_BAG_L1 -142.545018       0.619187   56.811127                0.619187          56.811127            1       True          8\n",
            "Number of models trained: 13\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
              "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L1': -131.46090891834504,\n",
              "  'LightGBM_BAG_L1': -131.054161598899,\n",
              "  'RandomForestMSE_BAG_L1': -116.54835939455667,\n",
              "  'CatBoost_BAG_L1': -130.70686471953755,\n",
              "  'ExtraTreesMSE_BAG_L1': -124.60067564699747,\n",
              "  'NeuralNetFastAI_BAG_L1': -142.5450180514693,\n",
              "  'WeightedEnsemble_L2': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L2': -60.25873304936424,\n",
              "  'LightGBM_BAG_L2': -55.180351624799606,\n",
              "  'RandomForestMSE_BAG_L2': -53.43893013209877,\n",
              "  'WeightedEnsemble_L3': -53.15998330370622},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/KNeighborsUnif_BAG_L1/',\n",
              "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/KNeighborsDist_BAG_L1/',\n",
              "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/LightGBMXT_BAG_L1/',\n",
              "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/LightGBM_BAG_L1/',\n",
              "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/RandomForestMSE_BAG_L1/',\n",
              "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/CatBoost_BAG_L1/',\n",
              "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/ExtraTreesMSE_BAG_L1/',\n",
              "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20230608_213303/models/NeuralNetFastAI_BAG_L1/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230608_213303/models/WeightedEnsemble_L2/',\n",
              "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20230608_213303/models/LightGBMXT_BAG_L2/',\n",
              "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20230608_213303/models/LightGBM_BAG_L2/',\n",
              "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20230608_213303/models/RandomForestMSE_BAG_L2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230608_213303/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.05951881408691406,\n",
              "  'KNeighborsDist_BAG_L1': 0.057946205139160156,\n",
              "  'LightGBMXT_BAG_L1': 94.24841284751892,\n",
              "  'LightGBM_BAG_L1': 43.16094613075256,\n",
              "  'RandomForestMSE_BAG_L1': 18.381736278533936,\n",
              "  'CatBoost_BAG_L1': 174.90212154388428,\n",
              "  'ExtraTreesMSE_BAG_L1': 10.604083776473999,\n",
              "  'NeuralNetFastAI_BAG_L1': 56.811126708984375,\n",
              "  'WeightedEnsemble_L2': 0.7061212062835693,\n",
              "  'LightGBMXT_BAG_L2': 78.31564164161682,\n",
              "  'LightGBM_BAG_L2': 36.187962770462036,\n",
              "  'RandomForestMSE_BAG_L2': 43.47725486755371,\n",
              "  'WeightedEnsemble_L3': 0.30775976181030273},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.07579684257507324,\n",
              "  'KNeighborsDist_BAG_L1': 0.08136701583862305,\n",
              "  'LightGBMXT_BAG_L1': 16.26093101501465,\n",
              "  'LightGBM_BAG_L1': 3.3201370239257812,\n",
              "  'RandomForestMSE_BAG_L1': 0.8608448505401611,\n",
              "  'CatBoost_BAG_L1': 0.18569183349609375,\n",
              "  'ExtraTreesMSE_BAG_L1': 0.8150298595428467,\n",
              "  'NeuralNetFastAI_BAG_L1': 0.6191868782043457,\n",
              "  'WeightedEnsemble_L2': 0.0036177635192871094,\n",
              "  'LightGBMXT_BAG_L2': 5.363943815231323,\n",
              "  'LightGBM_BAG_L2': 0.41321635246276855,\n",
              "  'RandomForestMSE_BAG_L2': 1.0338170528411865,\n",
              "  'WeightedEnsemble_L3': 0.00113677978515625},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
              " 0      WeightedEnsemble_L3  -53.159983      29.031099  556.514511   \n",
              " 1   RandomForestMSE_BAG_L2  -53.438930      23.252802  441.703147   \n",
              " 2          LightGBM_BAG_L2  -55.180352      22.632202  434.413855   \n",
              " 3        LightGBMXT_BAG_L2  -60.258733      27.582929  476.541534   \n",
              " 4    KNeighborsDist_BAG_L1  -84.125061       0.081367    0.057946   \n",
              " 5      WeightedEnsemble_L2  -84.125061       0.084985    0.764067   \n",
              " 6    KNeighborsUnif_BAG_L1 -101.546199       0.075797    0.059519   \n",
              " 7   RandomForestMSE_BAG_L1 -116.548359       0.860845   18.381736   \n",
              " 8     ExtraTreesMSE_BAG_L1 -124.600676       0.815030   10.604084   \n",
              " 9          CatBoost_BAG_L1 -130.706865       0.185692  174.902122   \n",
              " 10         LightGBM_BAG_L1 -131.054162       3.320137   43.160946   \n",
              " 11       LightGBMXT_BAG_L1 -131.460909      16.260931   94.248413   \n",
              " 12  NeuralNetFastAI_BAG_L1 -142.545018       0.619187   56.811127   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.001137           0.307760            3       True   \n",
              " 1                 1.033817          43.477255            2       True   \n",
              " 2                 0.413216          36.187963            2       True   \n",
              " 3                 5.363944          78.315642            2       True   \n",
              " 4                 0.081367           0.057946            1       True   \n",
              " 5                 0.003618           0.706121            2       True   \n",
              " 6                 0.075797           0.059519            1       True   \n",
              " 7                 0.860845          18.381736            1       True   \n",
              " 8                 0.815030          10.604084            1       True   \n",
              " 9                 0.185692         174.902122            1       True   \n",
              " 10                3.320137          43.160946            1       True   \n",
              " 11               16.260931          94.248413            1       True   \n",
              " 12                0.619187          56.811127            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          13  \n",
              " 1          12  \n",
              " 2          11  \n",
              " 3          10  \n",
              " 4           2  \n",
              " 5           9  \n",
              " 6           1  \n",
              " 7           5  \n",
              " 8           7  \n",
              " 9           6  \n",
              " 10          4  \n",
              " 11          3  \n",
              " 12          8  }"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j9QcFY84lWy"
      },
      "source": [
        "### Create predictions from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sJgRogsU4lWz",
        "outputId": "e75eaea3-7922-492b-e32a-3ae4f6f07e08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  Pred_count\n",
              "0  2011-01-20 00:00:00   22.357330\n",
              "1  2011-01-20 01:00:00   42.296539\n",
              "2  2011-01-20 02:00:00   45.607418\n",
              "3  2011-01-20 03:00:00   48.427540\n",
              "4  2011-01-20 04:00:00   50.547417"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d434a2fb-995c-4f19-a6e5-6d4f2483a834\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Pred_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>22.357330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>42.296539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>45.607418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>48.427540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>50.547417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d434a2fb-995c-4f19-a6e5-6d4f2483a834')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d434a2fb-995c-4f19-a6e5-6d4f2483a834 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d434a2fb-995c-4f19-a6e5-6d4f2483a834');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "predictions = predictor.predict(test)\n",
        "predictions = {'datetime': test['datetime'], 'Pred_count': predictions}\n",
        "predictions = pd.DataFrame(data=predictions)\n",
        "predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0acl0zmI4lWz"
      },
      "source": [
        "#### NOTE: Kaggle will reject the submission if we don't set everything to be > 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "StUcatVZ4lWz",
        "outputId": "df9c7f45-22d3-4c85-a194-949aedfc3b42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Pred_count\n",
              "count  6493.000000\n",
              "mean    100.806137\n",
              "std      89.854889\n",
              "min       3.194875\n",
              "25%      20.292889\n",
              "50%      63.529846\n",
              "75%     167.339478\n",
              "max     366.389923"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fabd7494-ee2e-47c5-9b61-5712ae2f82a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6493.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>100.806137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>89.854889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.194875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.292889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>63.529846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>167.339478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>366.389923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fabd7494-ee2e-47c5-9b61-5712ae2f82a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fabd7494-ee2e-47c5-9b61-5712ae2f82a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fabd7494-ee2e-47c5-9b61-5712ae2f82a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Describe the `predictions` series to see if there are any negative values\n",
        "predictions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "inUR5Vhx4lW0",
        "outputId": "68198d20-fad1-40d1-8423-9dd44aff2c12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [datetime, Pred_count]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88f69da8-7e4d-40eb-b18f-d32f4b0d3c38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Pred_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88f69da8-7e4d-40eb-b18f-d32f4b0d3c38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88f69da8-7e4d-40eb-b18f-d32f4b0d3c38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88f69da8-7e4d-40eb-b18f-d32f4b0d3c38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# How many negative values do we have?\n",
        "predictions[predictions['Pred_count']<0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0GwwynVh4lW0"
      },
      "outputs": [],
      "source": [
        "# Set them to zero\n",
        "predictions[predictions['Pred_count']<0] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTwWrnXA4lW1"
      },
      "source": [
        "### Set predictions to submission dataframe, save, and submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x_35za434lW1"
      },
      "outputs": [],
      "source": [
        "submission[\"count\"] = predictions['Pred_count']\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTpgwzL74lW1",
        "outputId": "2cd50491-1b22-47dd-9b9e-dfb79aaedc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 407kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"first raw submission\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLd_R7G4lW2"
      },
      "source": [
        "#### View submission via the command line or in the web browser under the competition's page - `My Submissions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDyec9ao4lW2",
        "outputId": "72e57311-b8af-4327-ed9d-f84caa354853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName        date                 description           status    publicScore  privateScore  \n",
            "--------------  -------------------  --------------------  --------  -----------  ------------  \n",
            "submission.csv  2023-06-08 21:53:39  first raw submission  complete  1.79590      1.79590       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP3-oGDf4lW2"
      },
      "source": [
        "#### Initial score of `1.79590`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbvPuz9Y4lW3"
      },
      "source": [
        "## Step 4: Exploratory Data Analysis and Creating an additional feature\n",
        "* Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "MzNNeXit4lXG",
        "outputId": "1369a063-fc7b-4ffd-eb9c-476e5e1c4df0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'season'}>,\n",
              "        <Axes: title={'center': 'holiday'}>,\n",
              "        <Axes: title={'center': 'workingday'}>],\n",
              "       [<Axes: title={'center': 'weather'}>,\n",
              "        <Axes: title={'center': 'temp'}>,\n",
              "        <Axes: title={'center': 'atemp'}>],\n",
              "       [<Axes: title={'center': 'humidity'}>,\n",
              "        <Axes: title={'center': 'windspeed'}>,\n",
              "        <Axes: title={'center': 'casual'}>],\n",
              "       [<Axes: title={'center': 'registered'}>,\n",
              "        <Axes: title={'center': 'count'}>, <Axes: >]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uT-r7354lXG",
        "outputId": "6b9a4ac3-2a91-4b70-8229-11bdcb70977b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-c025228d7c1e>:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  train.loc[:, \"datetime\"] = pd.to_datetime(train.loc[:, \"datetime\"])\n",
            "<ipython-input-23-c025228d7c1e>:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  test.loc[:, \"datetime\"] = pd.to_datetime(test.loc[:, \"datetime\"])\n"
          ]
        }
      ],
      "source": [
        "# create a new feature\n",
        "train.loc[:, \"datetime\"] = pd.to_datetime(train.loc[:, \"datetime\"])\n",
        "test.loc[:, \"datetime\"] = pd.to_datetime(test.loc[:, \"datetime\"])\n",
        "\n",
        "train['year'] = train['datetime'].dt.year\n",
        "train['month'] = train['datetime'].dt.month\n",
        "train['day'] = train['datetime'].dt.day\n",
        "train['hour'] = train['datetime'].dt.hour\n",
        "\n",
        "test['year'] = test['datetime'].dt.year\n",
        "test['month'] = test['datetime'].dt.month\n",
        "test['day'] = test['datetime'].dt.day\n",
        "test['hour'] = test['datetime'].dt.hour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDfImW6W4lXH"
      },
      "source": [
        "## Make category types for these so models know they are not just numbers\n",
        "* AutoGluon originally sees these as ints, but in reality they are int representations of a category.\n",
        "* Setting the dtype to category will classify these as categories in AutoGluon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "y36Sk6_t4lXI"
      },
      "outputs": [],
      "source": [
        "train[\"season\"] = train[\"season\"].astype(\"category\")\n",
        "train[\"weather\"] = train[\"weather\"].astype(\"category\")\n",
        "test[\"season\"] = test[\"season\"].astype(\"category\")\n",
        "test[\"weather\"] = test[\"weather\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yu-wDQKB4lXJ",
        "outputId": "a51295dd-2677-4552-d374-52bc89d70734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime season  holiday  workingday weather  temp   atemp  \\\n",
              "0 2011-01-01 00:00:00      1        0           0       1  9.84  14.395   \n",
              "1 2011-01-01 01:00:00      1        0           0       1  9.02  13.635   \n",
              "2 2011-01-01 02:00:00      1        0           0       1  9.02  13.635   \n",
              "3 2011-01-01 03:00:00      1        0           0       1  9.84  14.395   \n",
              "4 2011-01-01 04:00:00      1        0           0       1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  casual  registered  count  year  month  day  hour  \n",
              "0        81        0.0       3          13     16  2011      1    1     0  \n",
              "1        80        0.0       8          32     40  2011      1    1     1  \n",
              "2        80        0.0       5          27     32  2011      1    1     2  \n",
              "3        75        0.0       3          10     13  2011      1    1     3  \n",
              "4        75        0.0       0           1      1  2011      1    1     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed16ed64-5c2d-40df-93c1-265e05d79fc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed16ed64-5c2d-40df-93c1-265e05d79fc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed16ed64-5c2d-40df-93c1-265e05d79fc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed16ed64-5c2d-40df-93c1-265e05d79fc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# View are new feature\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "DKF2FWZ54lXK",
        "outputId": "259984d7-cb95-483a-826a-9b3a89c313dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'datetime'}>,\n",
              "        <Axes: title={'center': 'holiday'}>,\n",
              "        <Axes: title={'center': 'workingday'}>,\n",
              "        <Axes: title={'center': 'temp'}>],\n",
              "       [<Axes: title={'center': 'atemp'}>,\n",
              "        <Axes: title={'center': 'humidity'}>,\n",
              "        <Axes: title={'center': 'windspeed'}>,\n",
              "        <Axes: title={'center': 'casual'}>],\n",
              "       [<Axes: title={'center': 'registered'}>,\n",
              "        <Axes: title={'center': 'count'}>,\n",
              "        <Axes: title={'center': 'year'}>,\n",
              "        <Axes: title={'center': 'month'}>],\n",
              "       [<Axes: title={'center': 'day'}>,\n",
              "        <Axes: title={'center': 'hour'}>, <Axes: >, <Axes: >]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# View histogram of all features again now with the hour feature\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27cV6OrB4lXL"
      },
      "source": [
        "## Step 5: Rerun the model with the same settings as before, just with more features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dCJqAlN4lXM",
        "outputId": "6295849a-9561-4057-b0fa-8d7bf13aa12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230608_215739/\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230608_215739/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 13\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11054.57 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 2 | ['season', 'weather']\n",
            "\t\t('datetime', []) : 1 | ['datetime']\n",
            "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])      : 7 | ['holiday', 'workingday', 'humidity', 'year', 'month', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             : 2 | ['season', 'weather']\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 4 | ['humidity', 'month', 'day', 'hour']\n",
            "\t\t('int', ['bool'])            : 3 | ['holiday', 'workingday', 'year']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.3s = Fit runtime\n",
            "\t13 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.35s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.66s of the 599.64s of remaining time.\n",
            "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.4s of the 599.38s of remaining time.\n",
            "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 398.59s of the 598.56s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-34.346\t = Validation score   (-root_mean_squared_error)\n",
            "\t131.8s\t = Training   runtime\n",
            "\t25.37s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 253.94s of the 453.92s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-33.9173\t = Validation score   (-root_mean_squared_error)\n",
            "\t68.83s\t = Training   runtime\n",
            "\t8.13s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 178.03s of the 378.01s of remaining time.\n",
            "\t-38.3061\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.86s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 152.84s of the 352.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-35.4046\t = Validation score   (-root_mean_squared_error)\n",
            "\t143.29s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 5.78s of the 205.75s of remaining time.\n",
            "\t-38.3116\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.14s\t = Training   runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 192.14s of remaining time.\n",
            "\t-32.2575\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 191.7s of the 191.68s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.1156\t = Validation score   (-root_mean_squared_error)\n",
            "\t45.66s\t = Training   runtime\n",
            "\t1.55s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 141.26s of the 141.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-30.5397\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.76s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 95.44s of the 95.42s of remaining time.\n",
            "\t-31.6295\t = Validation score   (-root_mean_squared_error)\n",
            "\t48.21s\t = Training   runtime\n",
            "\t0.65s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 45.65s of the 45.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-30.9334\t = Validation score   (-root_mean_squared_error)\n",
            "\t56.39s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -17.51s of remaining time.\n",
            "\t-30.2798\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 617.9s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230608_215739/\")\n"
          ]
        }
      ],
      "source": [
        "predictor_new_features = TabularPredictor(\n",
        "    label=\"count\", problem_type=\"regression\", eval_metric=\"rmse\"\n",
        "    ).fit(\n",
        "    train_data=train.drop(['casual', 'registered'], axis=1),\n",
        "    time_limit=600,\n",
        "    presets='best_quality')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYwObGFl4lXN",
        "outputId": "2af01b61-6d1b-400d-e1bc-cd1b75286bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3  -30.279832      38.876900  568.694564                0.001127           0.319892            3       True         13\n",
            "1          LightGBM_BAG_L2  -30.539674      36.425390  418.115705                1.088107          37.763223            2       True         10\n",
            "2          CatBoost_BAG_L2  -30.933424      35.586213  436.740866                0.248930          56.388383            2       True         12\n",
            "3        LightGBMXT_BAG_L2  -31.115600      36.891048  426.012832                1.553766          45.660349            2       True          9\n",
            "4   RandomForestMSE_BAG_L2  -31.629516      35.984970  428.562716                0.647688          48.210234            2       True         11\n",
            "5      WeightedEnsemble_L2  -32.257516      34.656130  368.521766                0.001053           0.407632            2       True          8\n",
            "6          LightGBM_BAG_L1  -33.917339       8.132909   68.827613                8.132909          68.827613            1       True          4\n",
            "7        LightGBMXT_BAG_L1  -34.345997      25.369126  131.795204               25.369126         131.795204            1       True          3\n",
            "8          CatBoost_BAG_L1  -35.404622       0.304189  143.289893                0.304189         143.289893            1       True          6\n",
            "9   RandomForestMSE_BAG_L1  -38.306120       0.595273   23.858883                0.595273          23.858883            1       True          5\n",
            "10    ExtraTreesMSE_BAG_L1  -38.311570       0.587583   12.141568                0.587583          12.141568            1       True          7\n",
            "11   KNeighborsDist_BAG_L1  -84.125061       0.253580    0.342541                0.253580           0.342541            1       True          2\n",
            "12   KNeighborsUnif_BAG_L1 -101.546199       0.094623    0.096781                0.094623           0.096781            1       True          1\n",
            "Number of models trained: 13\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])             : 2 | ['season', 'weather']\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 4 | ['humidity', 'month', 'day', 'hour']\n",
            "('int', ['bool'])            : 3 | ['holiday', 'workingday', 'year']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
              "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L1': -34.34599701170154,\n",
              "  'LightGBM_BAG_L1': -33.91733862651761,\n",
              "  'RandomForestMSE_BAG_L1': -38.30612025079756,\n",
              "  'CatBoost_BAG_L1': -35.40462191757147,\n",
              "  'ExtraTreesMSE_BAG_L1': -38.31157013220686,\n",
              "  'WeightedEnsemble_L2': -32.25751590909092,\n",
              "  'LightGBMXT_BAG_L2': -31.11560036107481,\n",
              "  'LightGBM_BAG_L2': -30.53967405412639,\n",
              "  'RandomForestMSE_BAG_L2': -31.629515767074807,\n",
              "  'CatBoost_BAG_L2': -30.933423993798897,\n",
              "  'WeightedEnsemble_L3': -30.279831599489214},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/KNeighborsUnif_BAG_L1/',\n",
              "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/KNeighborsDist_BAG_L1/',\n",
              "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/LightGBMXT_BAG_L1/',\n",
              "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/LightGBM_BAG_L1/',\n",
              "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/RandomForestMSE_BAG_L1/',\n",
              "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/CatBoost_BAG_L1/',\n",
              "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20230608_215739/models/ExtraTreesMSE_BAG_L1/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230608_215739/models/WeightedEnsemble_L2/',\n",
              "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20230608_215739/models/LightGBMXT_BAG_L2/',\n",
              "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20230608_215739/models/LightGBM_BAG_L2/',\n",
              "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20230608_215739/models/RandomForestMSE_BAG_L2/',\n",
              "  'CatBoost_BAG_L2': 'AutogluonModels/ag-20230608_215739/models/CatBoost_BAG_L2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230608_215739/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.09678077697753906,\n",
              "  'KNeighborsDist_BAG_L1': 0.3425407409667969,\n",
              "  'LightGBMXT_BAG_L1': 131.79520392417908,\n",
              "  'LightGBM_BAG_L1': 68.82761263847351,\n",
              "  'RandomForestMSE_BAG_L1': 23.858883142471313,\n",
              "  'CatBoost_BAG_L1': 143.2898931503296,\n",
              "  'ExtraTreesMSE_BAG_L1': 12.141568183898926,\n",
              "  'WeightedEnsemble_L2': 0.40763211250305176,\n",
              "  'LightGBMXT_BAG_L2': 45.66034913063049,\n",
              "  'LightGBM_BAG_L2': 37.76322293281555,\n",
              "  'RandomForestMSE_BAG_L2': 48.21023368835449,\n",
              "  'CatBoost_BAG_L2': 56.38838315010071,\n",
              "  'WeightedEnsemble_L3': 0.31989216804504395},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.09462261199951172,\n",
              "  'KNeighborsDist_BAG_L1': 0.25358009338378906,\n",
              "  'LightGBMXT_BAG_L1': 25.369125843048096,\n",
              "  'LightGBM_BAG_L1': 8.132909297943115,\n",
              "  'RandomForestMSE_BAG_L1': 0.5952727794647217,\n",
              "  'CatBoost_BAG_L1': 0.30418920516967773,\n",
              "  'ExtraTreesMSE_BAG_L1': 0.5875825881958008,\n",
              "  'WeightedEnsemble_L2': 0.0010528564453125,\n",
              "  'LightGBMXT_BAG_L2': 1.5537657737731934,\n",
              "  'LightGBM_BAG_L2': 1.0881071090698242,\n",
              "  'RandomForestMSE_BAG_L2': 0.6476876735687256,\n",
              "  'CatBoost_BAG_L2': 0.2489302158355713,\n",
              "  'WeightedEnsemble_L3': 0.0011265277862548828},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
              " 0      WeightedEnsemble_L3  -30.279832      38.876900  568.694564   \n",
              " 1          LightGBM_BAG_L2  -30.539674      36.425390  418.115705   \n",
              " 2          CatBoost_BAG_L2  -30.933424      35.586213  436.740866   \n",
              " 3        LightGBMXT_BAG_L2  -31.115600      36.891048  426.012832   \n",
              " 4   RandomForestMSE_BAG_L2  -31.629516      35.984970  428.562716   \n",
              " 5      WeightedEnsemble_L2  -32.257516      34.656130  368.521766   \n",
              " 6          LightGBM_BAG_L1  -33.917339       8.132909   68.827613   \n",
              " 7        LightGBMXT_BAG_L1  -34.345997      25.369126  131.795204   \n",
              " 8          CatBoost_BAG_L1  -35.404622       0.304189  143.289893   \n",
              " 9   RandomForestMSE_BAG_L1  -38.306120       0.595273   23.858883   \n",
              " 10    ExtraTreesMSE_BAG_L1  -38.311570       0.587583   12.141568   \n",
              " 11   KNeighborsDist_BAG_L1  -84.125061       0.253580    0.342541   \n",
              " 12   KNeighborsUnif_BAG_L1 -101.546199       0.094623    0.096781   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.001127           0.319892            3       True   \n",
              " 1                 1.088107          37.763223            2       True   \n",
              " 2                 0.248930          56.388383            2       True   \n",
              " 3                 1.553766          45.660349            2       True   \n",
              " 4                 0.647688          48.210234            2       True   \n",
              " 5                 0.001053           0.407632            2       True   \n",
              " 6                 8.132909          68.827613            1       True   \n",
              " 7                25.369126         131.795204            1       True   \n",
              " 8                 0.304189         143.289893            1       True   \n",
              " 9                 0.595273          23.858883            1       True   \n",
              " 10                0.587583          12.141568            1       True   \n",
              " 11                0.253580           0.342541            1       True   \n",
              " 12                0.094623           0.096781            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          13  \n",
              " 1          10  \n",
              " 2          12  \n",
              " 3           9  \n",
              " 4          11  \n",
              " 5           8  \n",
              " 6           4  \n",
              " 7           3  \n",
              " 8           6  \n",
              " 9           5  \n",
              " 10          7  \n",
              " 11          2  \n",
              " 12          1  }"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "predictor_new_features.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vKblo5df4lXN",
        "outputId": "3491ba1f-e61a-42a6-f3ce-ba257d8b2150"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Pred_count\n",
              "count  6493.000000\n",
              "mean    161.497925\n",
              "std     141.743271\n",
              "min       2.428871\n",
              "25%      50.784718\n",
              "50%     124.648254\n",
              "75%     231.283203\n",
              "max     818.359192"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02bc7e0e-aab6-433b-8005-ca8e155949e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6493.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>161.497925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>141.743271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.428871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>50.784718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>124.648254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>231.283203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>818.359192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02bc7e0e-aab6-433b-8005-ca8e155949e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02bc7e0e-aab6-433b-8005-ca8e155949e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02bc7e0e-aab6-433b-8005-ca8e155949e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Remember to set all negative values to zero\n",
        "predictions_new_features = predictor_new_features.predict(test)\n",
        "predictions_new_features = {'datetime': test['datetime'], 'Pred_count': predictions_new_features}\n",
        "predictions_new_features = pd.DataFrame(data=predictions_new_features)\n",
        "predictions_new_features.head()\n",
        "# set all negative values to zero\n",
        "predictions_new_features[predictions_new_features['Pred_count']<0] = 0\n",
        "# view results\n",
        "predictions_new_features.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NR7udh0R4lXO"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_features = pd.read_csv('/content/submission.csv')\n",
        "submission_new_features[\"count\"] = predictions_new_features['Pred_count']\n",
        "submission_new_features.to_csv(\"submission_new_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU1En2yR4lXO",
        "outputId": "dbee8764-6c92-4df2-b4c0-e1af36fd45b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 448kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_features.csv -m \"new features\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HoDMudL4lXP",
        "outputId": "2234f6ff-69ef-4ae4-90bc-18efc53189da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description           status    publicScore  privateScore  \n",
            "---------------------------  -------------------  --------------------  --------  -----------  ------------  \n",
            "submission_new_features.csv  2023-06-08 22:21:32  new features          complete  0.62819      0.62819       \n",
            "submission.csv               2023-06-08 21:53:39  first raw submission  complete  1.79590      1.79590       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYLauPaj4lXQ"
      },
      "source": [
        "#### New Score of `0.62819`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iANH0F_L4lXR"
      },
      "source": [
        "## Step 6: Hyper parameter optimization\n",
        "* There are many options for hyper parameter optimization.\n",
        "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
        "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5uNzJpE4lXS",
        "outputId": "7e580faa-9e98-4aec-883a-e4c43a88d649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230608_222527/\"\n",
            "Presets specified: ['best_quality']\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230608_222527/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    10886\n",
            "Train Data Columns: 15\n",
            "Label Column: count\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Dropping user-specified ignored columns: ['casual', 'registered']\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11220.73 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 2 | ['season', 'weather']\n",
            "\t\t('datetime', []) : 1 | ['datetime']\n",
            "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])      : 7 | ['holiday', 'workingday', 'humidity', 'year', 'month', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             : 2 | ['season', 'weather']\n",
            "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "\t\t('int', [])                  : 4 | ['humidity', 'month', 'day', 'hour']\n",
            "\t\t('int', ['bool'])            : 3 | ['holiday', 'workingday', 'year']\n",
            "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "\t0.2s = Fit runtime\n",
            "\t13 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.6.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 2 L1 models ...\n",
            "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 179.87s of the 599.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: LightGBM_BAG_L1/T1 ...\n",
            "\t-40.2554\t = Validation score   (-root_mean_squared_error)\n",
            "\t30.21s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T2 ...\n",
            "\t-38.8609\t = Validation score   (-root_mean_squared_error)\n",
            "\t33.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T3 ...\n",
            "\t-38.5604\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T4 ...\n",
            "\t-121.9978\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L1/T5 ...\n",
            "\t-43.2111\t = Validation score   (-root_mean_squared_error)\n",
            "\t38.79s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 179.87s of the 429.03s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=21786, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21786, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:28:25,652\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=21877, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21877, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:28:36,809\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22023, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22023, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:28:45,663\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22131, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22131, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:28:51,912\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22224, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22224, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:03,130\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22333, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22333, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:11,473\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22439, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22439, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:19,984\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22568, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22568, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:29:31,963\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22720, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22720, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:39,475\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22816, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22816, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:49,559\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=22928, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22928, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:29:58,815\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23058, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23058, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:30:06,302\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23190, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23190, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:30:19,288\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23347, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23347, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:30:27,715\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23446, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23446, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:30:40,902\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23599, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23599, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:30:49,113\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23727, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23727, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:30:57,050\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23831, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23831, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:31:08,415\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=23949, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23949, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.99s of the 252.77s of remaining time.\n",
            "\t-38.081\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "2023-06-08 22:31:15,538\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.6.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 2 L2 models ...\n",
            "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 113.5s of the 252.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Fitted model: LightGBM_BAG_L2/T1 ...\n",
            "\t-36.722\t = Validation score   (-root_mean_squared_error)\n",
            "\t39.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L2/T2 ...\n",
            "\t-36.2611\t = Validation score   (-root_mean_squared_error)\n",
            "\t33.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM_BAG_L2/T3 ...\n",
            "\t-36.6337\t = Validation score   (-root_mean_squared_error)\n",
            "\t40.78s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 113.5s of the 138.52s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25282, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25282, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:33:16,425\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25377, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25377, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:33:27,602\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25488, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25488, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:33:36,502\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25626, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25626, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:33:43,318\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25715, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25715, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:33:55,748\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25835, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25835, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:34:03,221\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=25967, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25967, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:34:11,943\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=26071, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26071, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:34:23,697\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=26216, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26216, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:34:30,312\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=26389, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26389, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "2023-06-08 22:34:43,604\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=26495, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26495, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "2023-06-08 22:34:50,527\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=26592, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 43, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 101, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 248, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 540, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in after_all_folds_scheduled\n",
            "    raise processed_exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 505, in after_all_folds_scheduled\n",
            "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2309, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26592, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 374, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 156, in _fit\n",
            "    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 446, in generate_datasets\n",
            "    train_dataset = self.process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py\", line 511, in process_train_data\n",
            "    df = self.processor.fit_transform(df) # 2D numpy array\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1088, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 437, in fit_transform\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 878, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\", line 408, in fit\n",
            "    raise ValueError(\n",
            "ValueError: 'fill_value'=!missing! is invalid. Expected a numerical value when imputing numerical data\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 29.92s of remaining time.\n",
            "\t-36.1875\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 570.95s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230608_222527/\")\n"
          ]
        }
      ],
      "source": [
        "import autogluon.core as ag\n",
        "\n",
        "nn_options = {  # specifies non-default hyperparameters for nn models\n",
        "    'num_epochs': 10,  # number of training epochs\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True), \n",
        "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
        "    'layers': ag.space.Categorical([100], [1000], [200, 100], [300, 200, 100]),  # each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n",
        "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
        "}\n",
        "\n",
        "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
        "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
        "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
        "}\n",
        "\n",
        "hyperparameters = {\n",
        "                   'GBM': gbm_options,\n",
        "                   'NN': nn_options,  # comment this line out if you get errors on Mac OSX\n",
        "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
        "\n",
        "#num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
        "search_strategy = 'auto'  # to tune hyperparameters using Bayesian optimization routine with a local scheduler\n",
        "\n",
        "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}\n",
        "\n",
        "predictor_new_hpo = TabularPredictor(label=\"count\", eval_metric=\"root_mean_squared_error\",learner_kwargs={\"ignored_columns\":\n",
        "[\"casual\", \"registered\"]}).fit(train_data=train, time_limit=600, presets=\"best_quality\", hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlBMFgTC4lXT",
        "outputId": "1eba0664-4895-422d-ac45-9e7534b4d450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3  -36.187504       0.007873  245.581315                0.005116           0.793636            3       True         10\n",
            "1   LightGBM_BAG_L2/T2  -36.261091       0.002565  204.003624                0.000178          33.483718            2       True          8\n",
            "2   LightGBM_BAG_L2/T3  -36.633715       0.002579  211.303961                0.000193          40.784055            2       True          9\n",
            "3   LightGBM_BAG_L2/T1  -36.721958       0.002552  209.743378                0.000165          39.223472            2       True          7\n",
            "4  WeightedEnsemble_L2  -38.080972       0.001939   69.789824                0.001568           0.508701            2       True          6\n",
            "5   LightGBM_BAG_L1/T3  -38.560441       0.000166   36.108365                0.000166          36.108365            1       True          3\n",
            "6   LightGBM_BAG_L1/T2  -38.860855       0.000205   33.172759                0.000205          33.172759            1       True          2\n",
            "7   LightGBM_BAG_L1/T1  -40.255449       0.000168   30.214244                0.000168          30.214244            1       True          1\n",
            "8   LightGBM_BAG_L1/T5  -43.211088       0.000571   38.794755                0.000571          38.794755            1       True          5\n",
            "9   LightGBM_BAG_L1/T4 -121.997833       0.001277   32.229783                0.001277          32.229783            1       True          4\n",
            "Number of models trained: 10\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])             : 2 | ['season', 'weather']\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 4 | ['humidity', 'month', 'day', 'hour']\n",
            "('int', ['bool'])            : 3 | ['holiday', 'workingday', 'year']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'LightGBM_BAG_L1/T1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T3': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T4': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1/T5': 'StackerEnsembleModel_LGB',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBM_BAG_L2/T1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2/T2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2/T3': 'StackerEnsembleModel_LGB',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'LightGBM_BAG_L1/T1': -40.255448619289915,\n",
              "  'LightGBM_BAG_L1/T2': -38.86085503288153,\n",
              "  'LightGBM_BAG_L1/T3': -38.56044117734823,\n",
              "  'LightGBM_BAG_L1/T4': -121.99783255064257,\n",
              "  'LightGBM_BAG_L1/T5': -43.21108776368348,\n",
              "  'WeightedEnsemble_L2': -38.08097198249528,\n",
              "  'LightGBM_BAG_L2/T1': -36.721957533233955,\n",
              "  'LightGBM_BAG_L2/T2': -36.26109123604212,\n",
              "  'LightGBM_BAG_L2/T3': -36.633714655736476,\n",
              "  'WeightedEnsemble_L3': -36.18750372982533},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'LightGBM_BAG_L1/T1': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L1/T1/',\n",
              "  'LightGBM_BAG_L1/T2': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L1/T2/',\n",
              "  'LightGBM_BAG_L1/T3': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L1/T3/',\n",
              "  'LightGBM_BAG_L1/T4': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L1/T4/',\n",
              "  'LightGBM_BAG_L1/T5': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L1/T5/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20230608_222527/models/WeightedEnsemble_L2/',\n",
              "  'LightGBM_BAG_L2/T1': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L2/T1/',\n",
              "  'LightGBM_BAG_L2/T2': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L2/T2/',\n",
              "  'LightGBM_BAG_L2/T3': '/content/AutogluonModels/ag-20230608_222527/models/LightGBM_BAG_L2/T3/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20230608_222527/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'LightGBM_BAG_L1/T1': 30.21424436569214,\n",
              "  'LightGBM_BAG_L1/T2': 33.17275857925415,\n",
              "  'LightGBM_BAG_L1/T3': 36.108365058898926,\n",
              "  'LightGBM_BAG_L1/T4': 32.229782581329346,\n",
              "  'LightGBM_BAG_L1/T5': 38.79475545883179,\n",
              "  'WeightedEnsemble_L2': 0.5087008476257324,\n",
              "  'LightGBM_BAG_L2/T1': 39.22347164154053,\n",
              "  'LightGBM_BAG_L2/T2': 33.483718156814575,\n",
              "  'LightGBM_BAG_L2/T3': 40.78405499458313,\n",
              "  'WeightedEnsemble_L3': 0.7936360836029053},\n",
              " 'model_pred_times': {'LightGBM_BAG_L1/T1': 0.0001678466796875,\n",
              "  'LightGBM_BAG_L1/T2': 0.00020456314086914062,\n",
              "  'LightGBM_BAG_L1/T3': 0.00016617774963378906,\n",
              "  'LightGBM_BAG_L1/T4': 0.0012767314910888672,\n",
              "  'LightGBM_BAG_L1/T5': 0.0005714893341064453,\n",
              "  'WeightedEnsemble_L2': 0.001567840576171875,\n",
              "  'LightGBM_BAG_L2/T1': 0.00016498565673828125,\n",
              "  'LightGBM_BAG_L2/T2': 0.00017786026000976562,\n",
              "  'LightGBM_BAG_L2/T3': 0.0001926422119140625,\n",
              "  'WeightedEnsemble_L3': 0.005115509033203125},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'LightGBM_BAG_L1/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T3': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T4': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1/T5': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2/T1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2/T2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2/T3': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                  model   score_val  pred_time_val    fit_time  \\\n",
              " 0  WeightedEnsemble_L3  -36.187504       0.007873  245.581315   \n",
              " 1   LightGBM_BAG_L2/T2  -36.261091       0.002565  204.003624   \n",
              " 2   LightGBM_BAG_L2/T3  -36.633715       0.002579  211.303961   \n",
              " 3   LightGBM_BAG_L2/T1  -36.721958       0.002552  209.743378   \n",
              " 4  WeightedEnsemble_L2  -38.080972       0.001939   69.789824   \n",
              " 5   LightGBM_BAG_L1/T3  -38.560441       0.000166   36.108365   \n",
              " 6   LightGBM_BAG_L1/T2  -38.860855       0.000205   33.172759   \n",
              " 7   LightGBM_BAG_L1/T1  -40.255449       0.000168   30.214244   \n",
              " 8   LightGBM_BAG_L1/T5  -43.211088       0.000571   38.794755   \n",
              " 9   LightGBM_BAG_L1/T4 -121.997833       0.001277   32.229783   \n",
              " \n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                0.005116           0.793636            3       True   \n",
              " 1                0.000178          33.483718            2       True   \n",
              " 2                0.000193          40.784055            2       True   \n",
              " 3                0.000165          39.223472            2       True   \n",
              " 4                0.001568           0.508701            2       True   \n",
              " 5                0.000166          36.108365            1       True   \n",
              " 6                0.000205          33.172759            1       True   \n",
              " 7                0.000168          30.214244            1       True   \n",
              " 8                0.000571          38.794755            1       True   \n",
              " 9                0.001277          32.229783            1       True   \n",
              " \n",
              "    fit_order  \n",
              " 0         10  \n",
              " 1          8  \n",
              " 2          9  \n",
              " 3          7  \n",
              " 4          6  \n",
              " 5          3  \n",
              " 6          2  \n",
              " 7          1  \n",
              " 8          5  \n",
              " 9          4  }"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "predictor_new_hpo.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7IFWMZOZ4lXU"
      },
      "outputs": [],
      "source": [
        "# Remember to set all negative values to zero\n",
        "new_predictions_hpo = predictor_new_hpo.predict(test)\n",
        "new_predictions_hpo[new_predictions_hpo<0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XZ9qMbRN4lXV"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_hpo = pd.read_csv(\"sampleSubmission.csv\", parse_dates=[\"datetime\"])\n",
        "submission_new_hpo[\"count\"] = new_predictions_hpo\n",
        "submission_new_hpo.to_csv(\"submission_new_hpo.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnT_VjEw4lXX",
        "outputId": "a44a1193-d047-4da4-dfeb-51e56118b0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 327kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_hpo.csv -m \"new features with hyperparameters\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACd-duRq4lXY",
        "outputId": "2c66c18d-24db-40c3-936a-e2065a1bffa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description                        status    publicScore  privateScore  \n",
            "---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  \n",
            "submission_new_hpo.csv       2023-06-08 22:36:30  new features with hyperparameters  complete  0.48549      0.48549       \n",
            "submission_new_features.csv  2023-06-08 22:21:32  new features                       complete  0.62819      0.62819       \n",
            "submission.csv               2023-06-08 21:53:39  first raw submission               complete  1.79590      1.79590       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41v9Epzu4lXZ"
      },
      "source": [
        "#### New Score of `0.48549`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDjQ7vLO4lXa"
      },
      "source": [
        "## Step 7: Write a Report\n",
        "### Refer to the markdown file for the full report\n",
        "### Creating plots and table for report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4zxLbYyb4lXb",
        "outputId": "5044960d-3c0f-4222-bc60-2ed8d67aa281"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Taking the top model score from each training run and creating a line plot to show improvement\n",
        "# You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [53.159983, 30.279832, 36.187504 ]\n",
        "    }\n",
        ").plot(x=\"model\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_train_score.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "M3BVYdCC4lXc",
        "outputId": "b641b9fc-1933-4c05-f389-4231187a8708"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Take the 3 kaggle scores and creating a line plot to show improvement\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"test_eval\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [1.79590, 0.62819 , 0.48549]\n",
        "    }\n",
        ").plot(x=\"test_eval\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_test_score.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuikkcbs4lXc"
      },
      "source": [
        "### Hyperparameter table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "RZ6l4s7k4lXd",
        "outputId": "ca87f4a8-1218-444f-ac06-6564d5fb8421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          model                           hpo1           hpo2            hpo3  \\\n",
              "0       initial                   default_vals   default_vals    default_vals   \n",
              "1  add_features                   default_vals   default_vals    default_vals   \n",
              "2           hpo  GBM (Light gradient boosting)  XGB (XGBoost)  CAT (CATBoost)   \n",
              "\n",
              "     score  \n",
              "0  1.79590  \n",
              "1  0.62819  \n",
              "2  0.48549  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f697af66-7b7b-47ad-819a-74976a1f9f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>hpo1</th>\n",
              "      <th>hpo2</th>\n",
              "      <th>hpo3</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>initial</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>1.79590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>add_features</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>default_vals</td>\n",
              "      <td>0.62819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hpo</td>\n",
              "      <td>GBM (Light gradient boosting)</td>\n",
              "      <td>XGB (XGBoost)</td>\n",
              "      <td>CAT (CATBoost)</td>\n",
              "      <td>0.48549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f697af66-7b7b-47ad-819a-74976a1f9f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f697af66-7b7b-47ad-819a-74976a1f9f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f697af66-7b7b-47ad-819a-74976a1f9f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# The 3 hyperparameters we tuned with the kaggle score as the result\n",
        "pd.DataFrame({\n",
        "    \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "    \"hpo1\": ['default_vals','default_vals','GBM (Light gradient boosting)'],\n",
        "    \"hpo2\": ['default_vals', 'default_vals', 'XGB (XGBoost)'],\n",
        "    \"hpo3\": ['default_vals','default_vals','CAT (CATBoost)'],\n",
        "    \"score\": [1.79590, 0.62819 , 0.48549]\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}